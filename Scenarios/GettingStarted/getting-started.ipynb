{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Azure ML Data Prep SDK\n",
    "\n",
    "#### Note: Some features in this Notebook will _not_ work with the Private Preview version of the SDK; it assumes the Public Preview version.\n",
    "\n",
    "Wonder how you can make the most of the Azure ML Data Prep SDK? In this \"Getting Started\" guide, we'll showcase a few highlights that make this SDK shine for big datasets where `pandas` and `dplyr` can fall short. Using the [Ford GoBike dataset](https://www.fordgobike.com/system-data) as an example, we'll cover how to build Dataflows that allow you to:\n",
    "\n",
    "* [Read in data](#Read-in-data)\n",
    "* [Get a profile of your data](#Get-data-profile)\n",
    "* [Apply smart transforms by Microsoft Research](#Derive-by-example)\n",
    "* [Filter quickly](#Filter-our-data)\n",
    "* [Apply common data science transforms](#Transform-our-data)\n",
    "* [Easily handle errors and assertions](#Assert-on-invalid-data)\n",
    "* [Prepare your dataset for export and machine learning](#Export-for-machine-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from os import path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import pandas as pd\n",
    "import azureml.dataprep as dprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "Azure ML Data Prep supports many different file reading formats (i.e. CSV, Excel, Parquet), and also offers the ability to infer column types automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gobike = dprep\\\n",
    "    .read_csv(\n",
    "        path = 'https://dprepdata.blob.core.windows.net/demo/ford_gobike/2017-fordgobike-tripdata.csv',\n",
    "        inference_arguments = dprep.InferenceArguments.current_culture()\n",
    "    )\n",
    "gobike.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to iterate more quickly, we can take a sample of our data. Later, we can then apply the same transformations to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_gobike = gobike.take_sample(probability = 0.1, seed = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data profile\n",
    "\n",
    "Let's understand what our data looks like. Azure ML Data Prep facilitates this process by offering data profiles that help us glimpse into column types and column summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gobike.get_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_gobike.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we have quite a few missing values in `member_birth_year`. We also immediately see that we have some empty strings in our `member_gender` column. With the data profiler, we can quickly do a sanity check on our dataset and see where we might need to start data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive by example\n",
    "\n",
    "Azure ML Data Prep comes with additional \"smart\" transforms created by Microsoft Research. Here, we'll look at how you can derive a new column by providing examples of input-output pairs. Rather than explicitly using regular expressions to extract dates or hours from datetimes, we can provide examples for Azure ML Data Prep to learn what the pattern is. In fact, these smart transformations can also handle more complex derivations like inferring the day of the week from datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_derived = sampled_gobike\\\n",
    "    .to_string(\n",
    "        columns = ['start_time', 'end_time']\n",
    "    )\\\n",
    "    .derive_column_by_example(\n",
    "        source_columns = 'start_time',\n",
    "        new_column_name = 'date',\n",
    "        example_data = [('2017-12-31 16:57:39.6540', '2017-12-31'), ('2017-12-31 16:57:39', '2017-12-31')]\n",
    "    )\\\n",
    "    .derive_column_by_example(\n",
    "        source_columns = 'start_time',\n",
    "        new_column_name = 'hour',\n",
    "        example_data = [('2017-12-31 16:57:39.6540', '16')]\n",
    "    )\\\n",
    "    .derive_column_by_example(\n",
    "        source_columns = 'start_time',\n",
    "        new_column_name = 'wday',\n",
    "        example_data = [('2017-12-31 16:57:39.6540', 'Sunday')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter our data\n",
    "\n",
    "Let's verify that our derivations are correct by doing a bit of spot-checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_derived.filter(dprep.col('wday') != 'Sunday').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter on other column types; let's take a peek at rides that lasted over 5 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_derived.filter(dprep.col('duration_sec') > (60 * 60 * 5)).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform our data\n",
    "\n",
    "In addition to \"smart\" transformations, Azure ML Data Prep also supports many common data science transforms familiar to other industry-standard data science libraries. Here, we'll explore the ability to `summarize` and `replace`. We'll also get to use `join` when we handle assertions.\n",
    "\n",
    "#### Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_summary = sgb_derived\\\n",
    "    .summarize(\n",
    "        summary_columns = [\n",
    "            dprep\\\n",
    "                .SummaryColumnsValue(\n",
    "                    column_id = 'duration_sec', \n",
    "                    summary_column_name = 'duration_sec_mean', \n",
    "                    summary_function = dprep.SummaryFunction.MEAN\n",
    "                )\n",
    "        ],\n",
    "        group_by_columns = ['date']\n",
    "    )\n",
    "sgb_summary.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Data Prep also makes it easy to append this output of `summarize` to the original table based on the grouping variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgb_appended = sgb_derived\\\n",
    "    .summarize(\n",
    "        summary_columns = [\n",
    "            dprep\\\n",
    "                .SummaryColumnsValue(\n",
    "                    column_id = 'duration_sec', \n",
    "                    summary_column_name = 'duration_sec_mean', \n",
    "                    summary_function = dprep.SummaryFunction.MEAN\n",
    "                )\n",
    "        ],\n",
    "        group_by_columns = ['date'],\n",
    "        join_back = True\n",
    "    )\n",
    "sgb_appended.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace\n",
    "\n",
    "Recall that our `member_gender` column had empty strings that stood in place of `None`. Let's use our `replace` function to properly recode them as `None`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_replaced = sampled_gobike.replace_na(columns = ['member_gender'])\n",
    "sgb_replaced.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert on invalid data \n",
    "\n",
    "Azure ML Data Prep helps prevent broken pipelines and safeguard against bad data by supporting assertions. In our case, we'll create assertions to handle potentially erroneous `member_birth_year` values. The oldest person on record is no more than 130 years old, so birth year listed as before 1900 is wrong. Though our `sampled_gobike` dataset doesn't have any issues, we would fail on the full `gobike` dataset if we made that assumption. However, Azure ML Data Prep allows us to handle these gracefully with assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_asserted = gobike\\\n",
    "    .assert_value(\n",
    "        columns = 'member_birth_year', \n",
    "        expression = dprep.f_or(dprep.value.is_null(), dprep.value >= 1900),\n",
    "        error_code = 'InvalidDate'\n",
    "    )\n",
    "gb_asserted.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can filter to see what caused the 2 errors above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_errors = gb_asserted.filter(dprep.col('member_birth_year').is_error())\n",
    "gb_errors.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join\n",
    "But what were the original values? Let's use `join` to figure out what the values were that caused our assert to throw an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_errors.join(\n",
    "    left_dataflow = gb_errors,\n",
    "    right_dataflow = gobike,\n",
    "    join_key_pairs = [\n",
    "        ('duration_sec', 'duration_sec'),\n",
    "        ('start_station_id', 'start_station_id'),\n",
    "        ('bike_id', 'bike_id')\n",
    "    ]\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at `r_member_birth_year`, we see that these people were listed as being born in 1886. That's impossible! Now that we've identified outliers and anomalies, we can appropriately clean our data however we like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for machine learning\n",
    "\n",
    "One of the beautiful features of Azure ML Data Prep is that you only need to write your code once and choose whether to scale up or out; it takes care of figuring out how. To do so, you can export the `.dprep` file you've written tested on a smaller dataset, then run it with your larger dataset. Here, we show how you can export your new package. For a more detailed example on how to execute it on Spark, check out our [New York Taxicab scenario](https://github.com/Microsoft/PendletonDocs/blob/master/Scenarios/NYTaxiCab/01.new_york_taxi.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gobike = gobike.set_name(name = \"gobike\")\n",
    "package_path = path.join(mkdtemp(), \"gobike.dprep\")\n",
    "\n",
    "print(\"Saving package to: {}\".format(package_path))\n",
    "package = dprep.Package(arg = gobike)\n",
    "package.save(file_path = package_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want more information?\n",
    "\n",
    "Congratulations on finishing your introduction to the Azure ML Data Prep SDK! If you'd like more detailed tutorials on how to construct machine learning datasets or dive deeper into all of its functionality, you can find more information in our detailed notebooks [here](https://github.com/Microsoft/PendletonDocs). There, we cover topics including how to:\n",
    "\n",
    "* Cache your Dataflow to speed up your iterations\n",
    "* Add your custom Python transforms\n",
    "* Impute missing values\n",
    "* Sample your data\n",
    "* Reference and link between Dataflows\n",
    "* Apply your Dataflow to a new, larger data source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
